{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Optimized Quantum ML Training on Colab Pro\n",
        "## Target: 82% → 90% Accuracy with Trainable Quantum Layers\n",
        "\n",
        "This notebook is optimized for Google Colab Pro with A100 GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "check-gpu"
      },
      "source": [
        "# Cell 1: Check GPU and Request A100 if needed\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Check GPU\n",
        "gpu_info = subprocess.check_output(\"nvidia-smi\", shell=True).decode('utf-8')\n",
        "print(gpu_info)\n",
        "\n",
        "if 'A100' in gpu_info:\n",
        "    print(\"✅ A100 GPU detected - Optimal for quantum simulation!\")\n",
        "elif 'V100' in gpu_info:\n",
        "    print(\"✅ V100 GPU detected - Good for quantum simulation\")\n",
        "else:\n",
        "    print(\"⚠️ Consider factory resetting runtime to get A100/V100\")\n",
        "    print(\"Runtime -> Factory reset runtime -> Change runtime type -> GPU: A100\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mount-drive"
      },
      "source": [
        "# Cell 2: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Verify data exists\n",
        "import os\n",
        "data_path = '/content/drive/MyDrive/set'\n",
        "if os.path.exists(data_path):\n",
        "    print(f\"✅ Data found at {data_path}\")\n",
        "    print(f\"   Train: {os.path.exists(data_path + '/train')}\")\n",
        "    print(f\"   Test: {os.path.exists(data_path + '/test')}\")\n",
        "else:\n",
        "    print(f\"❌ Data not found at {data_path}\")\n",
        "    print(\"Please upload your dataset to Google Drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install-dependencies"
      },
      "source": [
        "# Cell 3: Install optimized dependencies\n",
        "!pip install torch torchvision --upgrade --quiet\n",
        "!pip install pennylane pennylane-lightning-gpu --quiet\n",
        "!pip install opencv-python scikit-learn tqdm matplotlib --quiet\n",
        "\n",
        "# Verify installations\n",
        "import torch\n",
        "import pennylane as qml\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"PennyLane version: {qml.__version__}\")\n",
        "\n",
        "# Test quantum device\n",
        "try:\n",
        "    dev = qml.device('lightning.gpu', wires=4)\n",
        "    print(\"✅ lightning.gpu quantum device ready\")\n",
        "except:\n",
        "    print(\"❌ lightning.gpu not available, using default.qubit\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clone-repo"
      },
      "source": [
        "# Cell 4: Clone or update repository\n",
        "repo_path = '/content/Quanvolutional-Neural-Network'\n",
        "\n",
        "if os.path.exists(repo_path):\n",
        "    print(\"Repository exists, pulling latest changes...\")\n",
        "    %cd {repo_path}\n",
        "    !git pull\n",
        "else:\n",
        "    print(\"Cloning repository...\")\n",
        "    !git clone https://github.com/YOUR_USERNAME/Quanvolutional-Neural-Network.git\n",
        "    %cd {repo_path}\n",
        "\n",
        "# List files to verify\n",
        "!ls -la src/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "configure-colab"
      },
      "source": [
        "# Cell 5: Configure for Colab with optimizations\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append('/content/Quanvolutional-Neural-Network')\n",
        "\n",
        "# Set environment variables for optimal performance\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "os.environ['PENNYLANE_COMPILE_CACHE'] = '1'  # Enable compilation cache\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "\n",
        "# Configure for maximum GPU utilization\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "print(\"✅ Colab optimizations configured\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prevent-disconnect"
      },
      "source": [
        "# Cell 6: Prevent disconnection (run in browser console)\n",
        "from IPython.display import Javascript\n",
        "\n",
        "display(Javascript('''\n",
        "function ClickConnect(){\n",
        "    console.log(\"Keeping Colab alive...\");\n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(ClickConnect, 60000)\n",
        "'''))\n",
        "\n",
        "print(\"✅ Keep-alive script activated\")\n",
        "print(\"Note: For longer training, also paste the script in browser console (F12)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Performance Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "benchmark"
      },
      "source": [
        "# Cell 7: Benchmark quantum simulation performance\n",
        "import time\n",
        "from src.trainable_quantum_model import create_enhanced_model\n",
        "\n",
        "device = torch.device('cuda')\n",
        "model = create_enhanced_model(circuit_type='data_reuploading').to(device)\n",
        "\n",
        "# Test batch\n",
        "batch_sizes = [32, 64, 128, 256]\n",
        "for bs in batch_sizes:\n",
        "    try:\n",
        "        x = torch.randn(bs, 1, 32, 32).to(device)\n",
        "        \n",
        "        # Warmup\n",
        "        _ = model(x)\n",
        "        torch.cuda.synchronize()\n",
        "        \n",
        "        # Time\n",
        "        start = time.time()\n",
        "        _ = model(x)\n",
        "        torch.cuda.synchronize()\n",
        "        elapsed = time.time() - start\n",
        "        \n",
        "        print(f\"Batch size {bs}: {elapsed:.3f}s ({bs/elapsed:.1f} samples/sec)\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Batch size {bs}: Out of memory\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\n✅ Recommended batch size: 128-256 for A100\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "main-training"
      },
      "source": [
        "# Cell 8: Main training with enhanced model\n",
        "from src.enhanced_training import run_enhanced_training\n",
        "from src.config import NUM_CLASSES\n",
        "\n",
        "# Configure training\n",
        "training_config = {\n",
        "    'circuit_type': 'data_reuploading',  # Best for accuracy\n",
        "    'num_epochs': 100,\n",
        "    'target_accuracy': 90.0,\n",
        "    'checkpoint_dir': '/content/drive/MyDrive/quantum_checkpoints'\n",
        "}\n",
        "\n",
        "print(\"Starting enhanced training...\")\n",
        "print(f\"Configuration: {training_config}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Run training\n",
        "best_val_acc, test_acc = run_enhanced_training(\n",
        "    circuit_type=training_config['circuit_type'],\n",
        "    num_epochs=training_config['num_epochs']\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Training Complete!\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "print(f\"Improvement over baseline: {best_val_acc - 82.0:.2f}%\")\n",
        "print(\"=\"*50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimental Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "experiments"
      },
      "source": [
        "# Cell 9: Run comprehensive experiments\n",
        "from experiments.run_experiments import ExperimentalFramework\n",
        "\n",
        "framework = ExperimentalFramework(\n",
        "    base_dir='/content/drive/MyDrive/quantum_experiments'\n",
        ")\n",
        "\n",
        "# Run specific experiment based on needs\n",
        "print(\"Select experiment to run:\")\n",
        "print(\"1. Baseline comparison (Fixed vs Trainable)\")\n",
        "print(\"2. Circuit architecture comparison\")\n",
        "print(\"3. Ablation study\")\n",
        "print(\"4. Gradient analysis\")\n",
        "\n",
        "# For automated run, uncomment desired experiment:\n",
        "# results = framework.run_baseline_comparison()\n",
        "# results = framework.run_circuit_comparison()\n",
        "# results = framework.run_ablation_study()\n",
        "# results = framework.run_gradient_analysis()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "visualization"
      },
      "source": [
        "# Cell 10: Visualize training progress\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "# Load training history\n",
        "checkpoint_dir = '/content/drive/MyDrive/quantum_checkpoints'\n",
        "history_file = f'{checkpoint_dir}/training_history.json'\n",
        "\n",
        "if os.path.exists(history_file):\n",
        "    with open(history_file, 'r') as f:\n",
        "        history = json.load(f)\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "    \n",
        "    # Loss curves\n",
        "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
        "    axes[0].plot(history['val_loss'], label='Val Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].set_title('Training Loss')\n",
        "    \n",
        "    # Accuracy curves\n",
        "    axes[1].plot(history['train_acc'], label='Train Acc')\n",
        "    axes[1].plot(history['val_acc'], label='Val Acc')\n",
        "    axes[1].axhline(y=82, color='r', linestyle='--', label='Baseline (82%)')\n",
        "    axes[1].axhline(y=90, color='g', linestyle='--', label='Target (90%)')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy (%)')\n",
        "    axes[1].legend()\n",
        "    axes[1].set_title('Training Accuracy')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print final stats\n",
        "    print(f\"Final Validation Accuracy: {history['val_acc'][-1]:.2f}%\")\n",
        "    print(f\"Best Validation Accuracy: {max(history['val_acc']):.2f}%\")\n",
        "    print(f\"Improvement: {max(history['val_acc']) - 82.0:.2f}%\")\n",
        "else:\n",
        "    print(\"No training history found. Run training first.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "save-model"
      },
      "source": [
        "# Cell 11: Save model for publication\n",
        "import torch\n",
        "from datetime import datetime\n",
        "\n",
        "# Create publication directory\n",
        "pub_dir = f'/content/drive/MyDrive/quantum_publication_models'\n",
        "os.makedirs(pub_dir, exist_ok=True)\n",
        "\n",
        "# Save with metadata\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "model_path = f'{pub_dir}/quantum_model_90pct_{timestamp}.pth'\n",
        "\n",
        "# Load best model\n",
        "best_model_path = f'{checkpoint_dir}/best_model.pth'\n",
        "if os.path.exists(best_model_path):\n",
        "    checkpoint = torch.load(best_model_path)\n",
        "    \n",
        "    # Add metadata\n",
        "    checkpoint['metadata'] = {\n",
        "        'baseline_accuracy': 82.0,\n",
        "        'achieved_accuracy': checkpoint.get('val_acc', 0),\n",
        "        'improvement': checkpoint.get('val_acc', 0) - 82.0,\n",
        "        'architecture': 'trainable_quantum_cnn',\n",
        "        'quantum_device': 'lightning.gpu',\n",
        "        'training_device': torch.cuda.get_device_name(0),\n",
        "        'timestamp': timestamp\n",
        "    }\n",
        "    \n",
        "    # Save\n",
        "    torch.save(checkpoint, model_path)\n",
        "    print(f\"✅ Model saved to {model_path}\")\n",
        "    print(f\"   Accuracy: {checkpoint['metadata']['achieved_accuracy']:.2f}%\")\n",
        "    print(f\"   Improvement: {checkpoint['metadata']['improvement']:.2f}%\")\n",
        "else:\n",
        "    print(\"No best model found. Complete training first.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup and Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "# Cell 12: Training summary and next steps\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING SESSION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "print(\"Results saved to Google Drive:\")\n",
        "print(f\"  - Checkpoints: /content/drive/MyDrive/quantum_checkpoints/\")\n",
        "print(f\"  - Experiments: /content/drive/MyDrive/quantum_experiments/\")\n",
        "print(f\"  - Final models: /content/drive/MyDrive/quantum_publication_models/\")\n",
        "print()\n",
        "print(\"Next steps:\")\n",
        "print(\"1. Download results to Mac for analysis\")\n",
        "print(\"2. Generate publication figures\")\n",
        "print(\"3. Run statistical significance tests\")\n",
        "print(\"4. Prepare manuscript with results\")\n",
        "print()\n",
        "print(\"To sync results to Mac:\")\n",
        "print(\"  rsync -av /path/to/drive/quantum_* ~/Desktop/results/\")\n",
        "print(\"=\"*60)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}