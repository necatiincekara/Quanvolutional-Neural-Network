# Hybrid Quantum-Classical Convolutional Neural Network for Ottoman-Turkish Character Recognition

A research-grade implementation of a hybrid quantum-classical neural network for classifying handwritten Ottoman-Turkish characters (44 classes). Built with PyTorch and PennyLane, leveraging GPU-accelerated quantum simulation and advanced training techniques.

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![PennyLane](https://img.shields.io/badge/PennyLane-0.32+-green.svg)](https://pennylane.ai/)

## ğŸ“ Project Overview

This project explores quantum machine learning (QML) for handwritten character recognition in historical scripts. Ottoman-Turkish characters present unique challenges due to high intra-class variance and complex morphology. Our hybrid architecture uses quantum circuits as trainable feature extractors, targeting quantum advantages in feature correlation learning.

**Research Goal**: Achieve â‰¥90% accuracy by evolving from fixed quantum layers (82% baseline from master's thesis) to fully trainable quantum circuits with advanced architectural innovations.

### ğŸ›ï¸ Current Best Architecture (V4)

Our model has evolved through 6 major iterations. **V4 provides the optimal balance** between training speed and accuracy:

```
Input (32Ã—32 grayscale)
    â†“
[Classical Preprocessing]
    Conv2d(1â†’4, stride=2) â†’ 16Ã—16
    MaxPool2d(2) â†’ 8Ã—8
    â†“
[Quantum Layer - 4 qubits]
    16 patches (2Ã—2 each)
    AngleEmbedding â†’ Rot gates â†’ CNOT chain
    16 quantum circuit evaluations/image
    â†“
[Classical Postprocessing]
    Conv2d(16â†’32) + GroupNorm
    Conv2d(32â†’64) + GroupNorm
    MaxPool2d(2)
    â†“
[Classification Head]
    Linear(64*features â†’ 64)
    Dropout(0.5)
    Linear(64 â†’ 44)
```

**Key Components**:
- **Vectorized Quantum Layer**: Batched processing of all image patches on GPU
- **GroupNorm**: Stable training with small effective batch sizes
- **Mixed Precision Training**: AMP for GPU efficiency
- **Per-Batch LR Scheduling**: Warmup + cosine annealing

### ğŸ§ª Evolution & Performance Benchmarks

| Version | Feature Map | Quantum Calls | Epoch Time | Accuracy | Status |
|---------|------------|---------------|------------|----------|---------|
| V1 | 32Ã—32 | 256 | >8h | 2.3% | âŒ Infeasible |
| V2 | 32Ã—32 (vec) | 256 | ~8h | 3.3% | âŒ Scheduler bug |
| V3 | 16Ã—16 | 64 | ~5.5h | 6.41% | âš ï¸ Learning |
| **V4** | **8Ã—8** | **16** | **~1.5h** | **8.75%** | **âœ… Stable** |
| V5 | 4Ã—4 | 4 | ~51s/batch | 2.04% | âŒ Info bottleneck |
| V6 | 6Ã—6 | 9 | ~117s/batch | 0.00% | âŒ Gradient vanish |

**Key Achievements**:
- âœ… **93.75% reduction** in quantum evaluations (256â†’16)
- âœ… **Vectorized implementation** enabling GPU parallelism
- âœ… **Stable training** with gradient flow diagnostics
- âœ… **Disk caching** for compiled quantum kernels

**Critical Findings**:
- ğŸ”´ **V6 failure**: Faster (43%) but gradient collapse prevents learning
- ğŸ”´ **Information bottleneck**: <8Ã—8 feature maps lose critical spatial information
- ğŸŸ¡ **Circuit expressivity**: Single-layer limits model capacity

### ğŸ“Š Current Status & Next Steps

**Stable Baseline**: V4 (8Ã—8 feature maps, 8.75% accuracy, 1.5h/epoch)

**Immediate Priorities** (see [docs/AUDIT_REPORT.md](docs/AUDIT_REPORT.md)):
1. **V7** (Week 1-2): Gradient stabilization â†’ Target 25% accuracy
2. **V8** (Week 3-4): Multi-scale processing â†’ Target 40% accuracy
3. **V9** (Week 5-6): Selective quantum â†’ Target 60% accuracy
4. **V10** (Week 7-8): Trainable quantum â†’ Target 90% accuracy

For detailed experimental results, see [docs/EXPERIMENTS.md](docs/EXPERIMENTS.md) | For implementation roadmap, see [docs/IMPLEMENTATION_GUIDE.md](docs/IMPLEMENTATION_GUIDE.md)

## ğŸš€ Getting Started

### Prerequisites

**Recommended Setup** (see [docs/COMPUTING_RESOURCES_2025.md](docs/COMPUTING_RESOURCES_2025.md) for details):

*   **Python 3.12.x** (or 3.13.x) - Full PyTorch 2.6+ and PennyLane 0.43+ support
*   **Google Colab Pro** with A100 GPU (CUDA 12.1) - Essential for quantum training
*   **VS Code** with Google Colab extension - Seamless local development + cloud execution
*   **Git** for version control

**Important**: M4 Mac Mini lacks CUDA support - cannot run `lightning.gpu` quantum simulator. Use Colab Pro for training.

### âš™ï¸ Installation

1.  **Clone the repository:**
    ```bash
    git clone <your-repository-url>
    cd Quanvolutional-Neural-Network
    ```

2.  **Install dependencies:** It is recommended to use a virtual environment.
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    pip install -r requirements.txt
    ```

3.  **Dataset:**
    This project expects a dataset of handwritten Ottoman characters located in a Google Drive folder. You must ensure your dataset is available at the paths specified in `src/config.py` (`TRAIN_PATH` and `TEST_PATH`). When running in Google Colab, you will need to mount your Drive.

### ğŸƒâ€â™€ï¸ Running the Training

The training script supports starting from scratch or resuming from a checkpoint.

*   **To start a new training session:**
    *   (Optional) If you want to ensure a clean start, delete any existing checkpoints: `rm -f models/checkpoint_latest.pth`
    *   Run the training script:
        ```bash
        python -m src.train
        ```

*   **To resume from the last checkpoint:**
    ```bash
    python -m src.train --resume
    ```
The script will automatically save the model with the best validation accuracy to `models/best_quanv_net.pth` and the latest state for resuming to `models/checkpoint_latest.pth`.

## ğŸ“ Project Structure

```
Quanvolutional-Neural-Network/
â”œâ”€â”€ src/                           # Core source code
â”‚   â”œâ”€â”€ config.py                  # Hyperparameters and paths
â”‚   â”œâ”€â”€ dataset.py                 # Ottoman character data loading
â”‚   â”œâ”€â”€ model.py                   # Base quantum-classical hybrid (V4/V6)
â”‚   â”œâ”€â”€ train.py                   # Training pipeline with AMP
â”‚   â”œâ”€â”€ trainable_quantum_model.py # Enhanced trainable circuits
â”‚   â””â”€â”€ enhanced_training.py       # Advanced training framework
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ AUDIT_REPORT.md            # Comprehensive codebase audit
â”‚   â”œâ”€â”€ EXPERIMENTS.md             # Detailed experimental log (V1-V6)
â”‚   â”œâ”€â”€ IMPLEMENTATION_GUIDE.md    # Step-by-step development guide
â”‚   â”œâ”€â”€ QUANTUM_ML_RECOMMENDATIONS.md  # QML best practices
â”‚   â”œâ”€â”€ RESEARCH_ROADMAP.md        # Publication roadmap
â”‚   â”œâ”€â”€ TRAINING_PLATFORM_GUIDE.md # Colab/Mac setup guides
â”‚   â””â”€â”€ COLAB_SETUP.md             # Google Colab configuration
â”œâ”€â”€ experiments/                   # Experimental scripts
â”‚   â””â”€â”€ run_experiments.py         # Automated ablation studies
â”œâ”€â”€ improved_model.py              # Alternative architectures
â”œâ”€â”€ improved_training.py           # Training optimizations
â”œâ”€â”€ improved_quantum_circuit.py    # Enhanced circuit designs
â”œâ”€â”€ performance_optimizations.py   # Benchmarking utilities
â”œâ”€â”€ models/                        # Saved checkpoints (created at runtime)
â”œâ”€â”€ CLAUDE.md                      # AI assistant instructions
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                      # This file
``` 